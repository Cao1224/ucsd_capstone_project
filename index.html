<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Ethics of Artificial Intelligence in Crime</title>
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'><text y='14' font-size='16'>üßë‚Äç‚öñÔ∏è</text></svg>">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <!-- Add Chart.js -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://unpkg.com/topojson@3"></script>
    <link rel="stylesheet" href="assets/styles.css" />
</head>

<body class="d-flex flex-column min-vh-100">

    <main class="flex-grow-1">
        <!-- Title -->
        <div class="container text-center my-5">
            <h1 class="fw-bolder">Ethics of Artificial Intelligence in Crime</h1>
            <p class="text-muted">UC San Diego Data Science Capstone 2025</p>
            <div class="d-flex justify-content-center flex-wrap">
                <a href="https://www.linkedin.com/in/cyc2025/" target="_blank" class="text-decoration-none">
                    <span class="btn btn-outline-primary m-2 px-3">Yuancheng (Kaleo) Cao</span>
                </a>

                <a href="https://www.linkedin.com/in/pukhrajfalak" target="_blank" class="text-decoration-none">
                    <span class="btn btn-outline-primary m-2 px-3">Aj Falak</span>
                </a>

                <a href="https://www.linkedin.com/in/kavya-sriram-1a440322b" target="_blank"
                    class="text-decoration-none">
                    <span class="btn btn-outline-primary m-2 px-3">Kavya Sriram</span>
                </a>

                <a href="https://www.linkedin.com/in/catherineback2" target="_blank" class="text-decoration-none">
                    <span class="btn btn-outline-primary m-2 px-3">Catherine Back</span>
                </a>
            </div>

            <div class="d-flex justify-content-center flex-wrap mt-1">
                <a href="https://www.linkedin.com/in/emily-ramond/" target="_blank" class="text-decoration-none">
                    <span class="btn btn-outline-secondary m-2 px-3">Emily Ramond<br><small><em>Mentor,
                                Deloitte</em></small></span>
                </a>
                <a href="https://www.linkedin.com/in/gregorythein/" target="_blank" class="text-decoration-none">
                    <span class="btn btn-outline-secondary m-2 px-3">Greg Thein<br><small><em>Mentor,
                                Deloitte</em></small></span>
                </a>
            </div>

            <div class="d-flex justify-content-center flex-wrap mt-1">
                <a href="https://github.com/cao1224/ucsd_capstone_project" target="_blank" class="text-decoration-none">
                    <span class="btn btn-dark m-2 px-3">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            class="bi bi-github" viewBox="0 0 16 16">
                            <path
                                d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8" />
                        </svg>
                        Code
                    </span>
                </a>

                <a href="" target="_blank" class="text-decoration-none">
                    <span class="btn btn-dark m-2 px-3">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            class="bi bi-file-earmark-pdf-fill" viewBox="0 0 16 16">
                            <path
                                d="M5.523 12.424q.21-.124.459-.238a8 8 0 0 1-.45.606c-.28.337-.498.516-.635.572l-.035.012a.3.3 0 0 1-.026-.044c-.056-.11-.054-.216.04-.36.106-.165.319-.354.647-.548m2.455-1.647q-.178.037-.356.078a21 21 0 0 0 .5-1.05 12 12 0 0 0 .51.858q-.326.048-.654.114m2.525.939a4 4 0 0 1-.435-.41q.344.007.612.054c.317.057.466.147.518.209a.1.1 0 0 1 .026.064.44.44 0 0 1-.06.2.3.3 0 0 1-.094.124.1.1 0 0 1-.069.015c-.09-.003-.258-.066-.498-.256M8.278 6.97c-.04.244-.108.524-.2.829a5 5 0 0 1-.089-.346c-.076-.353-.087-.63-.046-.822.038-.177.11-.248.196-.283a.5.5 0 0 1 .145-.04c.013.03.028.092.032.198q.008.183-.038.465z" />
                            <path fill-rule="evenodd"
                                d="M4 0h5.293A1 1 0 0 1 10 .293L13.707 4a1 1 0 0 1 .293.707V14a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2m5.5 1.5v2a1 1 0 0 0 1 1h2zM4.165 13.668c.09.18.23.343.438.419.207.075.412.04.58-.03.318-.13.635-.436.926-.786.333-.401.683-.927 1.021-1.51a11.7 11.7 0 0 1 1.997-.406c.3.383.61.713.91.95.28.22.603.403.934.417a.86.86 0 0 0 .51-.138c.155-.101.27-.247.354-.416.09-.181.145-.37.138-.563a.84.84 0 0 0-.2-.518c-.226-.27-.596-.4-.96-.465a5.8 5.8 0 0 0-1.335-.05 11 11 0 0 1-.98-1.686c.25-.66.437-1.284.52-1.794.036-.218.055-.426.048-.614a1.24 1.24 0 0 0-.127-.538.7.7 0 0 0-.477-.365c-.202-.043-.41 0-.601.077-.377.15-.576.47-.651.823-.073.34-.04.736.046 1.136.088.406.238.848.43 1.295a20 20 0 0 1-1.062 2.227 7.7 7.7 0 0 0-1.482.645c-.37.22-.699.48-.897.787-.21.326-.275.714-.08 1.103" />
                        </svg>
                        Paper (Coming Soon)
                    </span>
                </a>

                <a href="assets/poster.pdf" target="_blank" class="text-decoration-none">
                    <span class="btn btn-dark m-2 px-3">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            class="bi bi-image" viewBox="0 0 16 16">
                            <path d="M6.002 5.5a1.5 1.5 0 1 1-3 0 1.5 1.5 0 0 1 3 0" />
                            <path
                                d="M2.002 1a2 2 0 0 0-2 2v10a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2zm12 1a1 1 0 0 1 1 1v6.5l-3.777-1.947a.5.5 0 0 0-.577.093l-3.71 3.71-2.66-1.772a.5.5 0 0 0-.63.062L1.002 12V3a1 1 0 0 1 1-1z" />
                        </svg>
                        Poster
                    </span>
                </a>
            </div>
        </div>

        <section id="introduction" class="container my-5">
            <h2 class="">Introduction</h2>
            <p>The use of artificial intelligence (AI) in criminal justice, particularly in pretrial risk assessment,
                has
                raised concerns about bias. These algorithms predict the likelihood that a defendant will miss court or
                reoffend, affecting decisions such as bail eligibility. While intended to reduce human bias, they often
                reflect and amplify systemic inequalities in policing and arrest records. Ethical AI requires auditing
                models for biased error rates and outcomes. Without proper oversight, these systems can worsen
                inequalities instead of addressing them, ultimately eroding public trust in the legal system.
                Responsible AI in pretrial decisions must ensure fairness and accountability.</p>


            <h4>üö® Three Main Risks of ML in Pretrial Risk Assessment</h4>
            <div class="row g-4">

                <div class="col-md-4">
                    <div class="card h-100">
                        <div class="card-body text-center">
                            <div class="fs-1">üîç</div>
                            <h5 class="card-title mt-3">Biased Training Data</h5>
                            <p class="card-text">Over-policing in minority neighborhoods skews arrest records,
                                leading to misleading crime rate predictions.</p>
                        </div>
                    </div>
                </div>

                <div class="col-md-4">
                    <div class="card h-100">
                        <div class="card-body text-center">
                            <div class="fs-1">‚öñÔ∏è</div>
                            <h5 class="card-title mt-3">Proxy Discrimination</h5>
                            <p class="card-text">Even when race is excluded, variables like ZIP code or prior
                                arrests can act as hidden proxies, reinforcing bias.</p>
                        </div>
                    </div>
                </div>

                <div class="col-md-4">
                    <div class="card h-100">
                        <div class="card-body text-center">
                            <div class="fs-1">üîÑ</div>
                            <h5 class="card-title mt-3">Feedback Loop</h5>
                            <p class="card-text">Predictive models overestimate crime in minority areas, justifying
                                more policing and creating a cycle of biased data.</p>
                        </div>
                    </div>
                </div>

            </div>

            <p class="my-4">
                This work examines racial bias in pretrial risk assessments, where "reoffend" labels, often based on
                rearrest rates, misrepresent actual criminal behavior due to systemic policing biases. Black
                individuals, for example, face higher arrest rates for minor offenses than White individuals. Using
                Scikit-learn and AIF360 (AI Fairness 360), we audit and mitigate bias across the machine learning
                pipeline. Pre-processing techniques rebalance training data, while post-processing adjustments calibrate
                decision thresholds to equalize error rates. By integrating fairness-aware methods, our approach
                enhances transparency and reduces discriminatory outcomes in pretrial decision-making.
            </p>

        </section>

        <section id="dataset-overview" class="container my-5">
            <h2>Exploratory data analysis (EDA)</h2>

            <p>Our analysis utilizes the New York State Pretrial Release Dataset from 2023, comprising over
                285,000 cases. This comprehensive dataset includes demographic information, criminal history,
                court proceedings, and pretrial outcomes, offering valuable insights into the pretrial release
                system in New York State. The dataset underwent thorough cleaning and preprocessing, including
                handling of missing values, standardization of categorical variables, and validation of temporal
                data.</p>

            <div id="edaCanvas" class="card p-4">
                <div class="row">

                    <!-- Left Box: Description -->
                    <div class="col-md-6">
                        <!-- Rearrest Outcomes Description -->
                        <div id="rearrestOutcomesDesc" class="description-box">
                            <h4 class="text-start">Rearrest Outcomes Distribution</h4>
                            <p>This chart shows the distribution of rearrest outcomes during the pretrial period.
                                83.7% had no rearrest, 8.1% were rearrested for misdemeanors, 6.0% for non-violent
                                felonies,
                                and 2.2% for violent felonies.</p>
                        </div>

                        <!-- Race Description -->
                        <div id="raceDesc" class="description-box d-none">
                            <h4 class="text-start">Race Distribution</h4>
                            <p>This chart shows the racial breakdown of cases by reoffending status. Among White
                                individuals,
                                30% had no reoffense while 15% reoffended. For Black individuals, 25% had no reoffense
                                and 20%
                                reoffended. Asian individuals show 10% with no reoffense and 5% with reoffense. For
                                Other
                                individuals, 5% had no reoffense and 3% with reoffense.</p>
                        </div>

                        <!-- Ethnicity Description -->
                        <div id="ethnicityDesc" class="description-box d-none">
                            <h4 class="text-start">Ethnicity Distribution</h4>
                            <p>This chart displays ethnicity distribution by reoffending status. Among Hispanic
                                individuals,
                                35% had no reoffense while 12% reoffended. For Non-Hispanic individuals, 40% had no
                                reoffense and
                                13% reoffended. The data shows similar reoffending proportions between the two ethnic
                                categories.</p>
                        </div>

                        <!-- Gender Description -->
                        <div id="genderDesc" class="description-box d-none">
                            <h4 class="text-start">Gender Distribution</h4>
                            <p>This chart presents gender breakdown by reoffending status. Males show 45% with no
                                reoffense and 15%
                                with reoffense. Females show 30% with no reoffense and 10% with reoffense. Both genders
                                have similar
                                proportional reoffending rates, but males represent a larger portion of the overall
                                cases.</p>
                        </div>

                        <div id="caseDistributionDesc" class="description-box d-none">
                            <h4 class="text-start">Case Distribution by County</h4>
                            <p>This map visualizes how cases are distributed across New York counties. Darker colors
                                represent counties
                                with higher case counts, while lighter colors indicate fewer cases. Hovering over a
                                county displays its name
                                and total case count.</p>
                            <div id="legend" class="legend-container"></div>
                        </div>

                        <div id="priorHistoryImpactDesc" class="description-box d-none">
                            <h4 class="text-start">Impact of Prior Offenses</h4>
                            <p>This chart compares the reoffending rates between two groups: those with no prior
                                offenses (6.01%) and those
                                with prior offenses (10.18%). The bars represent the percentage of individuals in each
                                category who reoffended
                                during the pretrial period.</p>
                        </div>
                    </div>

                    <!-- Right Box: Visualization -->
                    <div class="col-md-6">
                        <!-- Rearrest Outcomes Visualization -->
                        <div id="rearrestOutcomesViz" class="visualization-box">
                            <canvas id="rearrestChart"></canvas>
                        </div>

                        <!-- Race Visualization -->
                        <div id="raceViz" class="visualization-box d-none">
                            <canvas id="raceChart"></canvas>
                        </div>

                        <!-- Ethnicity Visualization -->
                        <div id="ethnicityViz" class="visualization-box d-none">
                            <canvas id="ethnicityChart"></canvas>
                        </div>

                        <!-- Gender Visualization -->
                        <div id="genderViz" class="visualization-box d-none">
                            <canvas id="genderChart"></canvas>
                        </div>

                        <!-- Case Distribution Visualization -->
                        <div class="map-legend-container">
                            <div id="caseDistribution" class="chart-container d-none">
                                <svg id="countyMap"></svg>

                            </div>

                        </div>


                        <!-- Prior History Impact Visualization -->
                        <div id="priorHistoryImpact" class="visualization-box d-none">
                            <canvas id="priorOffenseChart"></canvas>
                        </div>
                    </div>
                </div>

                <!-- Navigation Buttons -->
                <div class="d-flex justify-content-between mt-4">
                    <button id="prevBtn" class="btn btn-secondary" disabled>Previous</button>
                    <button id="nextBtn" class="btn btn-primary">Next</button>
                </div>
            </div>
        </section>


        <section id="model-development" class="container my-5">
            <h2>Model Development</h2>

            <h4>Feature Engineering</h4>
            <p>The feature engineering process transformed raw pretrial data into predictive
                variables while minimizing bias. We created criminal history features
                capturing prior offense patterns, case characteristic variables describing
                current charges, and behavioral indicators reflecting past court compliance.
                We implemented log-transformation for skewed variables, one-hot encoding for
                categorical features, and standardization to ensure equal feature importance
                during model training.</p>

            <h4>Random Forest Model Development</h4>
            <p>Our Random Forest Classifier used 100 trees and was trained on seven key features
                selected for predicting pretrial reoffending. The model handled both numerical and
                categorical data effectively while capturing complex feature interactions.</p>

            <p>We binarized prior criminal history variables, converting count-based features
                into binary indicators (e.g., prior_misd_binary, prior_vfo_binary). The model
                was trained on a 50-30-20 split (training, validation, test), ensuring a
                balanced evaluation.</p>

            <p>Hyperparameters included max_depth=6, n_estimators=100, and random_state=42
                for reproducibility. The entropy criterion was used to maximize information
                gain, enhancing prediction reliability.</p>

            <h4>Model Performance</h4>
            <p>The Random Forest model achieved 83.27% overall accuracy, but balanced accuracy
                was only 50.67%, indicating poor performance on the minority class.</p>

            <p>For non-reoffenders (Class 0), the model performed well (precision: 0.84,
                recall: 0.99, F1-score: 0.91). However, for reoffenders (Class 1), recall
                was extremely low (0.02), meaning most reoffenders were misclassified.
                The ROC-AUC score was 0.6914, showing moderate discriminatory power.</p>

            <p>The model's imbalance favored non-reoffenders, highlighting the need for bias mitigation techniques to
                improve fairness and recall for reoffenders.</p>

            <h4>Feature Importance Analysis</h4>
            <p>Feature importance analysis revealed that the strongest predictors were:</p>

            <ul>
                <li>Age at Arrest - 48%</li>
                <li>Pending Misdemeanor Charges - 21%</li>
                <li>Pending Non-Violent Felony Charges - 11%</li>
                <li>Prior Misdemeanor Convictions - 7%</li>
                <li>Prior Non-Violent Felony Convictions - 3%</li>
            </ul>

            <h4>Addressing Imbalanced Labels</h4>
            <!-- Expand/Collapse Buttons -->
            <div class="d-flex justify-content-end my-2">
                <button id="expandAllBtn" class="btn btn-success me-2">Expand All</button>
                <button id="collapseAllBtn" class="btn btn-danger">Collapse All</button>
            </div>

            <!-- Bootstrap Accordion -->
            <div class="accordion" id="accordionExample">
                <!-- Accordion Item 1 -->
                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingOne">
                        <button class="accordion-button" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
                            1. Oversampling Techniques
                        </button>
                    </h2>
                    <div id="collapseOne" class="accordion-collapse collapse show" aria-labelledby="headingOne"
                        data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            We applied <strong>Random Oversampling</strong> and <strong>SMOTE (Synthetic Minority
                                Over-sampling
                                Technique)</strong>. SMOTE generates synthetic samples instead of duplicating existing
                            ones,
                            improving model generalization and preventing overfitting.
                        </div>
                    </div>
                </div>

                <!-- Accordion Item 2 -->
                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingTwo">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
                            2. Implementing SMOTE and Model Training
                        </button>
                    </h2>
                    <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo"
                        data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            We used <strong>imbalanced_make_pipeline</strong> to integrate SMOTE with a <strong>Random
                                Forest Classifier</strong>, setting <strong>class_weight='balanced'</strong> to adjust
                            the model's learning based on class distribution.
                        </div>
                    </div>
                </div>

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingThree">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
                            3. Hyperparameter Tuning
                        </button>
                    </h2>
                    <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree"
                        data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            We applied <strong>Stratified K-Fold Cross-Validation (k=5)</strong> and performed
                            <strong>Grid Search</strong> to
                            optimize <strong>n_estimators, max_depth, and random_state</strong>. Our final model
                            prioritized recall
                            for the minority class (reoffenders).
                        </div>
                    </div>
                </div>

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingFour">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
                            4. Optimized Parameters
                        </button>
                    </h2>
                    <div id="collapseFour" class="accordion-collapse collapse" aria-labelledby="headingFour"
                        data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            Best parameters found: <strong>max_depth=6, n_estimators=200, random_state=13.</strong>
                        </div>
                    </div>
                </div>

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingFive">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseFive" aria-expanded="false" aria-controls="collapseFive">
                            5. Results
                        </button>
                    </h2>
                    <div id="collapseFive" class="accordion-collapse collapse" aria-labelledby="headingFive"
                        data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            <p>After applying oversampling and fine-tuning, the model's ability to detect reoffenders
                                (Class 1) improved. However, there were trade-offs in performance for non-reoffenders
                                (Class 0).</p>

                            <!-- Performance Table -->
                            <div class="table-responsive">
                                <table class="table table-bordered text-center">
                                    <thead class="table-light">
                                        <tr>
                                            <th></th>
                                            <th class="class1-header">Recall (Class 1)</th>
                                            <th class="class1-header">Precision (Class 1)</th>
                                            <th class="class1-header">F1-Score (Class 1)</th>
                                            <th class="class0-header">Recall (Class 0)</th>
                                            <th class="class0-header">Precision (Class 0)</th>
                                            <th class="class0-header">F1-Score (Class 0)</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td><strong>Before Fine-Tuning</strong></td>
                                            <td>0.50</td>
                                            <td>0.26</td>
                                            <td>0.35</td>
                                            <td>0.73</td>
                                            <td>0.88</td>
                                            <td>0.80</td>
                                        </tr>
                                        <tr>
                                            <td><strong>After Fine-Tuning</strong></td>
                                            <td>0.66</td>
                                            <td>0.26</td>
                                            <td>0.38</td>
                                            <td>0.63</td>
                                            <td>0.90</td>
                                            <td>0.75</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>

                            <!-- Summary Insights -->
                            <strong>Summary Insights:</strong>
                            <ul class="mt-3">
                                <li><strong>Class 1 Improvement:</strong> Recall increased from 0.50 to 0.66, meaning
                                    the model now captures more actual reoffenders.</li>
                                <li><strong>Class 0 Trade-off:</strong> Precision slightly improved, but recall
                                    decreased from 0.73 to 0.63.</li>
                                <li><strong>Overall Balance:</strong> Balanced Accuracy improved to 0.6466, and the
                                    ROC-AUC score increased to 0.6914.</li>
                                <li>Fine-tuning resulted in a better trade-off between precision and recall, improving
                                    the detection of reoffenders while maintaining reasonable accuracy for
                                    non-reoffenders.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>



        </section>

        <section id="bias-mitigation" class="container my-5">
            <h2>Bias Mitigation</h2>
            <div class="row">
                <!-- Pre-processing: Reweighing -->
                <div class="col-md-6 mb-3">
                    <div class="card">
                        <div class="card-body">
                            <h5 class="card-title text-primary text-center"><i class="bi bi-arrow-repeat"></i>
                                Reweighing
                                (Pre-processing)</h5>
                            <p class="card-text">
                                Reweighing assigns different weights to dataset instances based on group membership,
                                ensuring
                                that underrepresented groups contribute more significantly to the model's learning
                                process.
                            </p>
                            <p><strong>Key Steps:</strong></p>
                            <ul>
                                <li>Assigns weights based on group membership (Race = 0 as unprivileged, Race = 1 as
                                    privileged).</li>
                                <li>Transforms the dataset by adjusting sample weights.</li>
                                <li>Trains the classifier on the reweighted dataset for fairer decision-making.</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Post-processing: Calibrated Equalized Odds -->
                <div class="col-md-6">
                    <div class="card">
                        <div class="card-body">
                            <h5 class="card-title text-success text-center"><i class="bi bi-balance-scale"></i>
                                Calibrated Equalized
                                Odds (Post-processing)</h5>
                            <p class="card-text">
                                This method modifies model predictions after training to balance false positive and
                                false negative rates across groups.
                            </p>
                            <p><strong>Key Steps:</strong></p>
                            <ul>
                                <li>Train the model on the original dataset (with oversampling applied).</li>
                                <li>Apply AIF360's calibration model to adjust predicted probabilities.</li>
                                <li>Ensure balanced false positive and false negative rates across racial groups.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>


            <h4 class="my-4">Fairness Metrics: Impact of Reweighing</h4>

            <!-- Summary Section -->
            <p><strong>Before reweighing:</strong> Before applying reweighing, the model was trained on the original
                dataset, which contained imbalances between the unprivileged and privileged groups. This led to
                disparities in fairness metrics, particularly in 1-min(DI, 1/DI), Statistical Parity Difference, and
                Average Odds Difference. The best Balanced Accuracy was achieved at a higher threshold of 0.49, but
                fairness trade-offs were observed.

            </p>
            <p><strong>After reweighing:</strong> After applying reweighing, the training dataset was adjusted by
                assigning different weights to instances based on group membership. This adjustment aimed to balance the
                learning process and reduce disparities in fairness metrics. As a result, the best Balanced Accuracy was
                achieved at a lower threshold (0.14), meaning the model needed less confidence to classify positive
                cases. Fairness improved across key metrics.</p>

            <!-- Expand/Collapse Buttons -->
            <div class="d-flex justify-content-end my-2">
                <button id="expandAllFairnessBtn" class="btn btn-success me-2">Expand All</button>
                <button id="collapseAllFairnessBtn" class="btn btn-danger">Collapse All</button>
            </div>

            <div class="accordion" id="accordionExample">
                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingBeforeWeighing">
                        <button class="accordion-button" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseBeforeWeighing" aria-expanded="true"
                            aria-controls="collapseBeforeWeighing">
                            Fairness Metrics (Before Reweighing)
                        </button>
                    </h2>
                    <div id="collapseBeforeWeighing" class="accordion-collapse-fairness collapse show"
                        aria-labelledby="headingBeforeWeighing" data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            <ul>
                                <li><strong>Threshold:</strong> 0.49 [This means that at a classification threshold of
                                    0.49, the model reached its highest balanced accuracy.]</li>
                                <li><strong>Best Balanced Accuracy:</strong> 0.6469 [The model correctly classified both
                                    groups 64.69% of the time.]</li>
                                <li><strong>1-min(DI, 1/DI):</strong> 0.0928 [A higher value indicates more disparity in
                                    disparate impact (DI).]</li>
                                <li><strong>Average Odds Difference:</strong> 0.0248 [Measures the difference in true
                                    positive rates and false positive rates across groups.
                                    ]</li>
                                <li><strong>Statistical Parity Difference:</strong> 0.0408 [Shows how much the
                                    probability of a positive prediction differs between groups.]</li>
                                <li><strong>Equal Opportunity Difference:</strong> 0.0059 [Measures the difference in
                                    true positive rates across groups.]</li>
                                <li><strong>Theil Index:</strong> 0.1159 [Measures overall inequality in predictions. A
                                    lower value is preferred.]</li>
                            </ul>
                            <p><strong>Key Takeaway: </strong> The fairness metrics suggest that before applying
                                reweighing, there was an imbalance in the way the model treated unprivileged and
                                privileged groups, particularly in disparate impact and statistical parity.</p>

                        </div>
                    </div>
                </div>

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingAfterWeighing">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                            data-bs-target="#collapseAfterWeighing" aria-expanded="false"
                            aria-controls="collapseAfterWeighing">
                            Fairness Metrics (After Reweighing)
                        </button>
                    </h2>
                    <div id="collapseAfterWeighing" class="accordion-collapse-fairness collapse"
                        aria-labelledby="headingAfterWeighing" data-bs-parent="#accordionExample">
                        <div class="accordion-body">
                            <ul>
                                <li><strong>Threshold:</strong> 0.14 [The model now reaches its highest balanced
                                    accuracy at a lower threshold, suggesting better calibration across groups.]</li>
                                <li><strong>Best Balanced Accuracy:</strong> 0.6351 [A slight drop compared to before
                                    (from 0.6469 to 0.6351), but fairness improved.]</li>
                                <li><strong>1-min(DI, 1/DI):</strong> 0.0542 [Decreased from 0.0928, indicating reduced
                                    disparity in disparate impact.]</li>
                                <li><strong>Average Odds Difference:</strong> 0.0079 [Improved, meaning the model now
                                    has a more balanced error rate across groups
                                    ]</li>
                                <li><strong>Statistical Parity Difference:</strong> 0.0235 [Lower than before, showing
                                    improved fairness in the probability of a positive prediction across groups.]</li>
                                <li><strong>Equal Opportunity Difference:</strong> -0.0107 [The change in equal
                                    opportunity difference indicates that the model's true positive rates are more
                                    aligned across groups.]</li>
                                <li><strong>Theil Index:</strong> 0.1193 [Slightly increased from 0.1159, suggesting a
                                    small trade-off in entropy-based fairness.]</li>
                            </ul>

                            <p><strong>Key Takeaway: </strong> </p>
                            <ul>
                                <li>
                                    Fairness improved across key metrics, particularly in disparate impact and average
                                    odds difference.
                                </li>
                                <li>
                                    Balanced Accuracy decreased slightly (from 64.69% to 63.51%), but this trade-off was
                                    acceptable for improving fairness.
                                </li>
                                <li>
                                    The lower classification threshold (from 0.49 to 0.14) suggests that the model now
                                    requires less confidence to classify positive cases, ensuring more equal treatment
                                    of both privileged and unprivileged groups.
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>

            <h4 class="my-4">Fairness Metrics: Impact of Calibrated Equalized Odds Postprocessing</h4>
            <!-- üìä Before & After Postprocessing Data Tables -->
            <div class="row my-4 ">
                <!-- Before Postprocessing Table -->
                <div class="col-md-6 mb-3">
                    <div class="card p-3">
                        <h6 class="card-title text-center">Before Postprocessing</h6>
                        <table class="table table-bordered text-center">
                            <thead class="table-light">
                                <tr>
                                    <th>Dataset</th>
                                    <th>GFPR Difference</th>
                                    <th>GFNR Difference</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Train Set</td>
                                    <td>0.0171</td>
                                    <td>0.0001</td>
                                </tr>
                                <tr>
                                    <td>Validation Set</td>
                                    <td>0.0167</td>
                                    <td>-0.0006</td>
                                </tr>
                                <tr>
                                    <td>Test Set</td>
                                    <td>0.0136</td>
                                    <td>0.0024</td>
                                </tr>
                            </tbody>
                        </table>
                        <p class="text-muted">Before postprocessing, the differences in <strong>false positive rates
                                (GFPR)</strong> and <strong>false negative rates (GFNR)</strong> indicate
                            <strong>disparities in model predictions</strong> across groups. The validation set shows a
                            <strong>0.0167 GFPR difference</strong>, meaning privileged groups had a lower false
                            positive rate than unprivileged groups. The <strong>GFNR difference is small</strong>, but
                            even slight imbalances can affect fairness.
                        </p>

                    </div>
                </div>

                <!-- After Postprocessing Table -->
                <div class="col-md-6">
                    <div class="card p-3">
                        <h6 class="card-title text-center">After Postprocessing</h6>
                        <table class="table table-bordered text-center">
                            <thead class="table-light">
                                <tr>
                                    <th>Dataset</th>
                                    <th>GFPR Difference</th>
                                    <th>GFNR Difference</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Validation Set</td>
                                    <td>0.0162</td>
                                    <td>-0.0001</td>
                                </tr>
                                <tr>
                                    <td>Test Set</td>
                                    <td>0.0132</td>
                                    <td>0.0031</td>
                                </tr>
                            </tbody>
                        </table>
                        <p class="text-muted">After postprocessing, <strong>GFPR differences reduced</strong>, with the
                            test set showing an improved <strong>0.0132 GFPR difference</strong>. The <strong>GFNR
                                difference slightly increased</strong> in the test set, but overall, disparities between
                            groups <strong>decreased</strong>, ensuring that <strong>privileged and unprivileged groups
                                were treated more equally</strong> in terms of misclassification rates.</p>

                    </div>
                </div>
            </div>

            <h5><strong>üí° Final Summary</strong></h5>
            <ul>
                <li>
                    Before Reweighing ‚Üí Higher accuracy, but fairness disparities in disparate impact & statistical
                    parity.
                </li>
                <li>After Reweighing ‚Üí Improved fairness, but a slight drop in accuracy due to balancing efforts.
                </li>
                <li>
                    Main Trade-off: Fairness increased, but Theil Index showed minor fluctuation, indicating a small
                    increase in prediction uncertainty.
                </li>
                <li>Fairness Improvement: GFPR and GFNR differences reduced after postprocessing.</li>
                <li>Balanced Accuracy Trade-off: Postprocessing did not significantly impact
                    balanced accuracy, meaning the model maintained its overall predictive performance.</li>
                <li>Comparison with Reweighing: Unlike reweighing, which adjusts the training
                    data, postprocessing modifies model predictions directly. This approach ensures fairness
                    without altering data distributions, making it a better option for models deployed in
                    production, where maintaining original data integrity is important. If fairness constraints must be
                    met without
                    modifying training data, postprocessing is preferable.</li>
            </ul>
        </section>

        <section id="conclusion" class="container my-5">
            <h2>Conclusion</h2>

            <p>This research examines the application of machine learning fairness techniques to mitigate racial bias
                in pretrial risk assessment algorithms. Our initial random forest model achieved 83.27% accuracy but
                demonstrated poor balanced accuracy (50.67%) and severely underperformed on the minority class of
                reoffenders,
                with age at arrest emerging as the strongest predictor. We implemented a bias mitigation strategy that
                combining
                dataset rebalancing through SMOTE, reweighing to equalize outcomes between privileged and unprivileged
                groups,
                and calibrated equalized odds to balance error rate differences. These interventions improved the
                model's
                balanced accuracy to 64.66% and significantly increased recall for reoffenders from 0.02 to 0.66,
                demonstrating more equitable performance across racial groups while highlighting the inherent trade-offs
                between accuracy and fairness.

                Our findings highlight the challenges of predicting reoffending fairly and accurately. This improved
                model
                can help policymakers and criminal justice stakeholders develop more eqitable risk assessment tools
                that reduce bias while maintaining model performance. This research contributes to the field of fairness
                in machine learning by demonstrating the trade-off between accuracy and fairness in decisions that
                affect
                many lives. It emphasizes the importance of balancing model performance with ethical considerations. By
                applying fairness metrics and debiasing techniques, this study provides insight into addressing bias in
                predictive modeling within the criminal justice system.</p>
        </section>

    </main>


    <footer class="footer mt-auto py-3 bg-body-tertiary">
        <div class="container d-flex justify-content-between align-items-center">
            <span class="text-body-secondary">Supported by UC San Diego Halƒ±cƒ±oƒülu Data Science Institute</span>
            <div>
                <a href="" class="me-3 text-body-secondary" target="_blank" aria-label="Paper">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor"
                        class="bi bi-file-earmark-pdf-fill" viewBox="0 0 20 20">
                        <path
                            d="M5.523 12.424q.21-.124.459-.238a8 8 0 0 1-.45.606c-.28.337-.498.516-.635.572l-.035.012a.3.3 0 0 1-.026-.044c-.056-.11-.054-.216.04-.36.106-.165.319-.354.647-.548m2.455-1.647q-.178.037-.356.078a21 21 0 0 0 .5-1.05 12 12 0 0 0 .51.858q-.326.048-.654.114m2.525.939a4 4 0 0 1-.435-.41q.344.007.612.054c.317.057.466.147.518.209a.1.1 0 0 1 .026.064.44.44 0 0 1-.06.2.3.3 0 0 1-.094.124.1.1 0 0 1-.069.015c-.09-.003-.258-.066-.498-.256M8.278 6.97c-.04.244-.108.524-.2.829a5 5 0 0 1-.089-.346c-.076-.353-.087-.63-.046-.822.038-.177.11-.248.196-.283a.5.5 0 0 1 .145-.04c.013.03.028.092.032.198q.008.183-.038.465z" />
                        <path fill-rule="evenodd"
                            d="M4 0h5.293A1 1 0 0 1 10 .293L13.707 4a1 1 0 0 1 .293.707V14a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2m5.5 1.5v2a1 1 0 0 0 1 1h2zM4.165 13.668c.09.18.23.343.438.419.207.075.412.04.58-.03.318-.13.635-.436.926-.786.333-.401.683-.927 1.021-1.51a11.7 11.7 0 0 1 1.997-.406c.3.383.61.713.91.95.28.22.603.403.934.417a.86.86 0 0 0 .51-.138c.155-.101.27-.247.354-.416.09-.181.145-.37.138-.563a.84.84 0 0 0-.2-.518c-.226-.27-.596-.4-.96-.465a5.8 5.8 0 0 0-1.335-.05 11 11 0 0 1-.98-1.686c.25-.66.437-1.284.52-1.794.036-.218.055-.426.048-.614a1.24 1.24 0 0 0-.127-.538.7.7 0 0 0-.477-.365c-.202-.043-.41 0-.601.077-.377.15-.576.47-.651.823-.073.34-.04.736.046 1.136.088.406.238.848.43 1.295a20 20 0 0 1-1.062 2.227 7.7 7.7 0 0 0-1.482.645c-.37.22-.699.48-.897.787-.21.326-.275.714-.08 1.103" />
                    </svg>
                </a>
                
                <a href="https://github.com/cao1224/ucsd_capstone_project" class="text-body-secondary" target="_blank"
                    aria-label="GitHub">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor"
                        class="bi bi-github" viewBox="0 0 16 16">
                        <path
                            d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8" />
                    </svg>
                </a>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js"
        integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js"
        integrity="sha384-0pUGZvbkm6XF6gxjEnlmuGrJXVbNuzT9qBBavbLwCsOGabYfZo0T0to5eqruptLy"
        crossorigin="anonymous"></script>


    <script src="script.js"></script>

    <script>
        const expandAllBtn = document.getElementById("expandAllBtn");
        const collapseAllBtn = document.getElementById("collapseAllBtn");
        const accordionItems = document.querySelectorAll(".accordion-collapse");

        expandAllBtn.addEventListener("click", () => {
            accordionItems.forEach(item => {
                new bootstrap.Collapse(item, { toggle: false }).show();
            });
        });

        collapseAllBtn.addEventListener("click", () => {
            accordionItems.forEach(item => {
                new bootstrap.Collapse(item, { toggle: false }).hide();
            });
        });

        const expandAllFairnessBtn = document.getElementById("expandAllFairnessBtn");
        const collapseAllFairnessBtn = document.getElementById("collapseAllFairnessBtn");
        const accordionFairnessItems = document.querySelectorAll(".accordion-collapse-fairness");

        expandAllFairnessBtn.addEventListener("click", () => {
            accordionFairnessItems.forEach(item => {
                new bootstrap.Collapse(item, { toggle: false }).show();
            });
        });

        collapseAllFairnessBtn.addEventListener("click", () => {
            accordionFairnessItems.forEach(item => {
                new bootstrap.Collapse(item, { toggle: false }).hide();
            });
        });    
    </script>
</body>

</html>